{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(Path('D:/Development/Data/datasets/csv/mnist_train_small.csv'), delimiter=',')\n",
    "test_data = np.loadtxt(Path('D:/Development/Data/datasets/csv/mnist_test.csv'), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n_classes: int, idx: int) -> np.ndarray:\n",
    "    encoding = np.zeros(n_classes)\n",
    "    encoding[idx] = 1.0\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (28, 28)\n",
    "img_size = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:,1:] / 255.0\n",
    "y_train = np.array([one_hot(10, int(i)) for i in train_data[:,0]])\n",
    "\n",
    "x_test = test_data[:,1:] / 255.0\n",
    "y_test = np.array([one_hot(10, int(i)) for i in test_data[:,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define activation functions, derivatives and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def dsigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def softmax(x: np.ndarray) -> float:\n",
    "    y = np.exp(x)\n",
    "    return y / np.sum(y)\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def cross_entropy(p: np.ndarray, q: np.ndarray) -> float:\n",
    "    return -np.sum(p * np.log(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPeceptron:\n",
    "    def __init__(self, n_in: int, n_h: int, n_out: int) -> None:\n",
    "        self.W1: np.ndarray = np.random.uniform(-1, 1, (n_h, n_in))\n",
    "        self.b1: np.ndarray = np.zeros(n_h)\n",
    "\n",
    "        self.W2: np.ndarray = np.random.uniform(-1, 1, (n_out, n_h))\n",
    "        self.b2: np.ndarray = np.zeros(n_out)\n",
    "    \n",
    "    @property\n",
    "    def shape(self) -> tuple:\n",
    "        return (self.W1.shape, self.W2.shape)\n",
    "\n",
    "    @property\n",
    "    def parameters(self) -> tuple[np.ndarray]:\n",
    "        return (self.W1, self.b1, self.W2, self.b2)\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        h = sigmoid(self.W1 @ x + self.b1)\n",
    "        return softmax(self.W2 @ h + self.b2)\n",
    "    \n",
    "    def save(self, fp: Path) -> None:\n",
    "        np.savez(fp, w1=self.W1, b1=self.b1, w2=self.W2, b2=self.b2)\n",
    "\n",
    "    def load(self, fp: Path) -> None:\n",
    "        params = np.load(fp)\n",
    "        self.W1, self.b1 = params['w1'], params['b1']\n",
    "        self.W2, self.b2 = params['w2'], params['b2']\n",
    "\n",
    "\n",
    "def loss(model: MultilayerPeceptron, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    Y_hat = np.array([model.forward(x) for x in X])\n",
    "    return np.mean([cross_entropy(y, y_hat) for (y, y_hat) in zip(Y, Y_hat)])\n",
    "\n",
    "\n",
    "def accuracy(model: MultilayerPeceptron, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    n_true_pos = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        y_pred = model.forward(x)\n",
    "        n_true_pos += 1 if np.argmax(y_pred) == np.argmax(y) else 0\n",
    "    return n_true_pos / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath=True)\n",
    "def calculate_grads(parameters: tuple[np.ndarray], X: np.ndarray, Y: np.ndarray) -> tuple[np.ndarray]:\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    dW1, db1 = np.zeros(W1.shape), np.zeros(b1.shape)\n",
    "    dW2, db2 = np.zeros(W2.shape), np.zeros(b2.shape)\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        u = W1 @ X[i] + b1\n",
    "        h = sigmoid(u)\n",
    "        y = softmax(W2 @ h + b2)\n",
    "        \n",
    "        dLdy = y - Y[i]\n",
    "        dLdu = W2.T @ dLdy * dsigmoid(u)\n",
    "\n",
    "        dW1 += np.outer(dLdu, X[i])\n",
    "        db1 += dLdu\n",
    "\n",
    "        dW2 += np.outer(dLdy, h)\n",
    "        db2 += dLdy\n",
    "\n",
    "    n = len(X)\n",
    "    dW1, db1 = dW1/n, db1/n\n",
    "    dW2, db2 = dW2/n, db2/n\n",
    "\n",
    "    return (dW1, db1, dW2, db2)\n",
    "\n",
    "\n",
    "def train(model: MultilayerPeceptron, x_train: np.ndarray, y_train: np.ndarray, lr, batch_size, max_epoch) -> None:\n",
    "    n_samples = len(x_train)\n",
    "    n_batches = n_samples // batch_size\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        batches = np.array_split(np.random.permutation(n_samples), n_batches)\n",
    "        \n",
    "        for batch in batches:\n",
    "            dW1, db1, dW2, db2 = calculate_grads(model.parameters, x_train[batch], y_train[batch])\n",
    "            \n",
    "            model.W1 -= lr * dW1\n",
    "            model.b1 -= lr * db1\n",
    "\n",
    "            model.W2 -= lr * dW2\n",
    "            model.b2 -= lr * db2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained loss: 2.609\n",
      "trained loss: 0.792\n",
      "test set accuracy: 78.2%\n"
     ]
    }
   ],
   "source": [
    "n_in = 784\n",
    "n_h = 10\n",
    "n_out = 10\n",
    "\n",
    "learning_rate = 1e-1\n",
    "batch_size = 64\n",
    "max_epoch = 4\n",
    "\n",
    "model = MultilayerPeceptron(n_in, n_h, n_out)\n",
    "\n",
    "print(f\"untrained loss: {round(loss(model, x_test, y_test), 3)}\")\n",
    "train(model, x_train, y_train, learning_rate, batch_size, max_epoch)\n",
    "print(f\"trained loss: {round(loss(model, x_test, y_test), 3)}\")\n",
    "\n",
    "model_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"test set accuracy: {round(model_accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save, load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path('D:/Development/Data/tmp/weights.npz')\n",
    "model.save(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilayerPeceptron(n_in, n_h, n_out)\n",
    "model.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.792\n",
      "accuracy: 78.2%\n"
     ]
    }
   ],
   "source": [
    "model_loss = loss(model, x_test, y_test)\n",
    "model_accuracy = accuracy(model, x_test, y_test)\n",
    "\n",
    "print(f\"loss: {round(model_loss, 3)}\")\n",
    "print(f\"accuracy: {round(model_accuracy * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
